{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12234, 3)\n"
     ]
    }
   ],
   "source": [
    "pcd_path = \"data/kinth/pointcloud/1720509720.141261339.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "pcd = pcd.remove_radius_outlier(nb_points=25, radius=0.2)[0] # (pcd, new indexed from old)\n",
    "points = np.asarray(pcd.points)\n",
    "\n",
    "print(points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe2st(\n",
    "    points: np.ndarray,\n",
    "    voxel_size: float,\n",
    "    stage1_radius: float,\n",
    "    stage2_border: float,\n",
    "    stage1_thresh: float=0.7,\n",
    "    stage2_thresh: float=0.3\n",
    "):\n",
    "    '''\n",
    "    Perform filtration with a two-stage pipeline, one PCA and one statistical.\n",
    "\n",
    "    Params:\n",
    "    - points (np.ndarray): [n, 3] xyz coordinates\n",
    "    - voxel_size (float): voxel size for voxel downsample\n",
    "    - stage1_radius (float): search radius of sphere neighbour to perform PCA\n",
    "    - stage2_border (float): search border of square neighbour to perform statistic\n",
    "\n",
    "    Return:\n",
    "    - points (np.ndarray): [n, 3] xyz coordinates after clustered\n",
    "    - labels (np.ndarray): [n,] cluster labels of each point\n",
    "    '''\n",
    "    \n",
    "    # voxel downsample\n",
    "    points, _, _, _ = utils.voxel_downsample(points, voxel_size, use_avg=False)\n",
    "    \n",
    "    # do the stage 1\n",
    "    stage1_feat_list = []\n",
    "    search_tree = o3d.geometry.KDTreeFlann(utils.npy2o3d(points))\n",
    "    for query_idx in tqdm(range(len(points)), total=len(points), ncols=100):\n",
    "        query = points[query_idx]\n",
    "        neighbour_num, neighbour_idx_list, _ = search_tree.search_radius_vector_3d(query, stage1_radius)\n",
    "        if neighbour_num <= 3:\n",
    "            stage1_feat_list.append([0.0, 0.0])\n",
    "            continue\n",
    "        eigvals, eigvecs = utils.pca_k(points[neighbour_idx_list], 3)\n",
    "        assert eigvals[0] >= eigvals[1] and eigvals[1] >= eigvals[2]\n",
    "        feat = np.array([\n",
    "            (eigvals[0] - eigvals[1]) / (eigvals[0] + 1e-9),\n",
    "            (eigvals[1] - eigvals[2]) / (eigvals[1] + 1e-9)\n",
    "        ])\n",
    "        feat = feat / feat.sum()\n",
    "        stage1_feat_list.append(feat)\n",
    "    stage1_feat_list = np.array(stage1_feat_list)\n",
    "    \n",
    "    # do the stage 2\n",
    "    stage2_feat_list = []\n",
    "    for query_idx in tqdm(range(len(points)), total=len(points), ncols=100):\n",
    "        query = points[query_idx]\n",
    "        mask = (\n",
    "            (np.abs(points[:, 0] - query[0]) < stage2_border / 2.0) &\n",
    "            (np.abs(points[:, 1] - query[1]) < stage2_border / 2.0) &\n",
    "            (np.abs(points[:, 2] - query[2]) < stage2_border)\n",
    "        )\n",
    "        mask[query_idx] = False\n",
    "        vicinity = points[mask]\n",
    "        if len(vicinity) < 3:\n",
    "            stage2_feat_list.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        feat = (1.0 - utils.sin_batch(points[mask] - query, np.array([0, 0, 1]))).mean()\n",
    "        stage2_feat_list.append(feat)\n",
    "    stage2_feat_list = np.array(stage2_feat_list)\n",
    "\n",
    "    # do the filtration\n",
    "    mask1 = (stage1_feat_list[:, 1] > stage1_thresh)\n",
    "    mask2 = (stage2_feat_list > stage2_thresh)\n",
    "    mask_filtered = mask1 & mask2\n",
    "    points_filtered = points[mask_filtered]\n",
    "    mask_denoised = utils.radius_filter(points_filtered, 0.2, 20)\n",
    "    points_denoised = points_filtered[mask_denoised] \n",
    "\n",
    "    # do the dbscan cluster\n",
    "    cluster_label = np.array(utils.npy2o3d(points_denoised).cluster_dbscan(eps=0.20, min_points=30))\n",
    "    \n",
    "    return points_denoised, cluster_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/7677 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 7677/7677 [00:00<00:00, 13360.73it/s]\n",
      "100%|████████████████████████████████████████████████████████| 7677/7677 [00:00<00:00, 12525.85it/s]\n"
     ]
    }
   ],
   "source": [
    "points_clustered, labels_clustered = pipe2st(points, 0.02, 0.15, 0.40)\n",
    "# do the color map\n",
    "norm = plt.Normalize(labels_clustered.min(), labels_clustered.max())\n",
    "cmap = matplotlib.colormaps[\"hsv\"]\n",
    "colors_clustered = (cmap(norm(labels_clustered))[:, :3] * 255.0).astype(np.int32)\n",
    "\n",
    "utils.npy2ply(points_clustered, colors_clustered, \"data/output/clustered.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw bounding box for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "draw_vtx = []\n",
    "draw_clr = []\n",
    "draw_seq = []\n",
    "for label in range(labels_clustered.max() + 1):\n",
    "    bbox_points, bbox_seq = utils.aabb_draw_meta(points_clustered[labels_clustered == label])\n",
    "    bbox_colors = (np.ones(bbox_points.shape) * cmap(norm(label))[:3] * 255.0).astype(np.int32)\n",
    "    draw_seq.append(bbox_seq + len(draw_vtx) * 8 + len(points_clustered)) # need vertex offset\n",
    "    draw_vtx.append(bbox_points)\n",
    "    draw_clr.append(bbox_colors)\n",
    "draw_vtx = np.concatenate(draw_vtx, axis=0)\n",
    "draw_clr = np.concatenate(draw_clr, axis=0)\n",
    "draw_seq = np.concatenate(draw_seq, axis=0)\n",
    "\n",
    "ply_vtx = PlyElement.describe(\n",
    "    utils.join_struct_arrays([\n",
    "        np.core.records.fromarrays(\n",
    "            np.concatenate([points_clustered, draw_vtx], axis=0).transpose(),\n",
    "            dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')]\n",
    "        ),\n",
    "        np.core.records.fromarrays(\n",
    "            np.concatenate([colors_clustered, draw_clr], axis=0).transpose(),\n",
    "            dtype=[('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]\n",
    "        )\n",
    "    ]),\n",
    "    name = \"vertex\"\n",
    ")\n",
    "\n",
    "ply_edg = PlyElement.describe(\n",
    "    data=np.core.records.fromarrays(\n",
    "        draw_seq.transpose(),\n",
    "        dtype=[('vertex1', 'u4'), ('vertex2', 'u4')]\n",
    "    ),\n",
    "    name=\"edge\"\n",
    ")\n",
    "\n",
    "ply_data = PlyData([ply_vtx, ply_edg], text=False)\n",
    "ply_data.write(\"data/output/bbox_test.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.12.1+cuda-11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
